{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Ai32e-DMLYA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive, userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KQeDo76vh4C"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "# Set working directory to the src folder\n",
        "os.chdir('/content/drive/MyDrive/thesis_src')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2vuQG0_nvvaq"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVAN99qSOrTM"
      },
      "outputs": [],
      "source": [
        "# --- Model Configuration ---\n",
        "BASE_MODEL_NAME = 'facebook/m2m100_418M'\n",
        "MODEL_TYPE = 'bart'\n",
        "SOURCE_LANG_CODE = 'ha'  # Use lang code if using BART family models\n",
        "TARGET_LANG_CODE = 'ha'\n",
        "HUB_MODEL_ID = 'ahmadmwali/m2m100_418M_Hausa'  # Model id on HF Hub\n",
        "\n",
        "# --- Training Parameters ---\n",
        "NUM_EPOCHS = 5\n",
        "LR = 2e-5\n",
        "WEIGHT_DECAY = 1e-3\n",
        "GRADIENT_ACCUMULATION_STEPS = 4\n",
        "TRAIN_BATCH_SIZE = 1\n",
        "EVAL_BATCH_SIZE = 1\n",
        "\n",
        "# --- LoRA Parameters ---\n",
        "LORA_LR = 2e-4\n",
        "LORA_R = 16\n",
        "LORA_ALPHA = 32\n",
        "LORA_DROPOUT = 0.05\n",
        "\n",
        "# --- Dataset Sizes ---\n",
        "TRAIN_SIZE = 5000\n",
        "VAL_SIZE = 1000\n",
        "TEST_SIZE = 1000\n",
        "\n",
        "# --- File Paths ---\n",
        "TRAIN_FILE = '/content/drive/MyDrive/thesis_data/train.tsv'\n",
        "VAL_FILE = '/content/drive/MyDrive/thesis_data/validation.tsv'\n",
        "TEST_FILE = \"/content/drive/MyDrive/thesis_data/test.tsv\"\n",
        "\n",
        "# --- Output Directories ---\n",
        "OUTPUT_DIR_BASE = os.path.join('/content/drive/MyDrive/train_results/', 'results_'+ MODEL_TYPE)\n",
        "RESULTS_DIR_BASE = \"/content/drive/MyDrive/test_results\"\n",
        "\n",
        "# --- Hugging Face Token ---\n",
        "# Setting my HF token. You can get it from https://huggingface.co/settings/tokens\n",
        "token = userdata.get('HUGGING_FACE_HUB_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahGNXAcdvto3"
      },
      "outputs": [],
      "source": [
        "# Run the training script.\n",
        "!python train.py \\\n",
        "    --model_type $MODEL_TYPE \\\n",
        "    --base_model_name $BASE_MODEL_NAME \\\n",
        "    --train_size $TRAIN_SIZE \\\n",
        "    --val_size $VAL_SIZE \\\n",
        "    --train_file $TRAIN_FILE \\\n",
        "    --val_file $VAL_FILE \\\n",
        "    --learning_rate $LR \\\n",
        "    --output_dir_base $OUTPUT_DIR_BASE \\\n",
        "    --hub_model_id_prefix $HUB_MODEL_ID \\\n",
        "    --num_epochs $NUM_EPOCHS \\\n",
        "    --lora_learning_rate $LORA_LR \\\n",
        "    --lora_r $LORA_R \\\n",
        "    --lora_alpha $LORA_ALPHA \\\n",
        "    --lora_dropout $LORA_DROPOUT \\\n",
        "    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \\\n",
        "    --train_batch_size $TRAIN_BATCH_SIZE \\\n",
        "    --eval_batch_size $EVAL_BATCH_SIZE \\\n",
        "    --weight_decay $WEIGHT_DECAY \\\n",
        "    --use_lora \\\n",
        "    --hf_token $token \\\n",
        "    --push_to_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k7-3-APqNmog"
      },
      "outputs": [],
      "source": [
        "# Manually push the model to HF Hub. This is because the --push_to_hub\n",
        "# training arg pushes only the readme file without the model and tokenizer.\n",
        "from huggingface_hub import HfApi, login, create_repo\n",
        "from huggingface_hub.utils import HfHubHTTPError\n",
        "\n",
        "best_checkpoint_path = os.path.join(OUTPUT_DIR_BASE, 'm2m100_418M-full/checkpoint-186')\n",
        "api = HfApi()\n",
        "commit_message = 'Manual upload of Model and tokenizer from best checkpoint'\n",
        "\n",
        "# Attempt to create the repository, ignore if it already exists\n",
        "try:\n",
        "    create_repo(repo_id='ahmadmwali/m2m100_418M-test1', repo_type=\"model\", exist_ok=True, token=token)\n",
        "    print(f\"Repository {HUB_MODEL_ID} ensured to exist.\")\n",
        "except HfHubHTTPError as e:\n",
        "    print(f\"Error creating repository (or it might be private and inaccessible): {e}\")\n",
        "\n",
        "# Upload the folder contents\n",
        "try:\n",
        "    api.upload_folder(\n",
        "        folder_path=best_checkpoint_path,\n",
        "        repo_id='ahmadmwali/m2m100_418M-test',\n",
        "        repo_type=\"model\",\n",
        "        commit_message=commit_message,\n",
        "        token=token\n",
        "    )\n",
        "    print(f\"Manually uploaded contents of {best_checkpoint_path} to {HUB_MODEL_ID}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during upload: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCaqxTN7ngfM"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set.\n",
        "!python test.py \\\n",
        "    --model_type $MODEL_TYPE \\\n",
        "    --hub_model_id $HUB_MODEL_ID \\\n",
        "    --test_file $TEST_FILE \\\n",
        "    --results_dir_base $RESULTS_DIR_BASE \\\n",
        "    --source_lang_code $SOURCE_LANG_CODE \\\n",
        "    --target_lang_code $TARGET_LANG_CODE \\\n",
        "    --hf_token $token \\\n",
        "    --test_size $TEST_SIZE \\\n",
        "    --is_lora_adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1SWG1ktSzm8"
      },
      "outputs": [],
      "source": [
        "# Visualize train and eval logs using Tensorboard. Wandb may be used as well.\n",
        "# Colab comes with Tensorboard out of the box, it may need to be installed\n",
        "# if working on a different environment using !pip install tensorboard.\n",
        "log_dir_path = os.path.join(OUTPUT_DIR_BASE, BASE_MODEL_NAME.split('/')[1], 'logs')\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $log_dir_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5R-xD5KvJuB"
      },
      "outputs": [],
      "source": [
        "# Run this on any dataframe you want to clean.\n",
        "!python predict_on_dataframe.py \\\n",
        "    --model_type bart \\\n",
        "    --hub_model_id $HUB_MODEL_ID \\\n",
        "    --is_lora_adapter \\\n",
        "    --base_model_name_for_lora $BASE_MODEL_NAME \\\n",
        "    --input_file $TEST_FILE \\\n",
        "    --output_file \"/content/drive/MyDrive/thesis_data/downstream.tsv\" \\\n",
        "    --input_text_column \"tweet\" \\\n",
        "    --prediction_column_name \"new_tweet\" \\\n",
        "    --prediction_batch_size 16 \\\n",
        "    --max_seq_length 256 \\\n",
        "    --max_new_tokens 256 \\\n",
        "    --num_beams 4 \\\n",
        "    --file_separator \"\\t\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkWy5H5KDVHP"
      },
      "outputs": [],
      "source": [
        "!python evaluate_downstream.py \\\n",
        "    --file-path \"/content/drive/MyDrive/thesis_data/downstream.tsv\" \\\n",
        "    --tweet-col \"tweet\" \\\n",
        "    --cleaned-col \"new_tweet\" \\\n",
        "    --label-col 'label' \\\n",
        "    --learning-rate 1e-5 \\\n",
        "    --model-checkpoint \"castorini/afriberta_base\" \\\n",
        "    --num-epochs 5 \\\n",
        "    --batch-size 8 \\\n",
        "    --output-dir \"/content/drive/MyDrive/Results/downstream_m2m_400M_results\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMYZEZ3d8PC3iaUpHUxRmNh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}